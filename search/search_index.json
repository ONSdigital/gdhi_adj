{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"gdhi-adj","text":"<p>This site contains the project documentation for <code>gdhi-adj</code>, a project  that flags outliers of GDHI data at LSOA levels and adjusts the outlier values.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ol> <li>API Reference</li> </ol> <p>Quickly find what you're looking for depending on your use case by looking at the different pages.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>The following prerequisites are required for <code>gdhi-adj</code>:</p> <ul> <li>Python 3.12 or higher</li> </ul>"},{"location":"#contact","title":"\ud83d\udcec Contact","text":"<p>For questions, support, or feedback about <code>gdhi-adj</code>, please email RDSA.Support@ons.gov.uk.</p>"},{"location":"reference/","title":"API Reference","text":"<p>This part of the project documentation focuses on an information-oriented approach. Use it as a reference for the technical implementation of the <code>gdhi-adj</code> codebase.</p>"},{"location":"reference/#main-pipeline","title":"Main Pipeline","text":""},{"location":"reference/#gdhi_adj.pipeline","title":"<code>gdhi_adj.pipeline</code>","text":"<p>Title for pipeline.py module</p>"},{"location":"reference/#gdhi_adj.pipeline.run_pipeline","title":"<code>run_pipeline(config_path)</code>","text":"<p>Run the GDHI adjustment pipeline. Args:     config_path (str): Path to the configuration file.</p>"},{"location":"reference/#preprocessing","title":"Preprocessing","text":""},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess","title":"<code>gdhi_adj.preprocess.calc_preprocess</code>","text":"<p>Module for calculations to preprocess data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_iqr","title":"<code>calc_iqr(df: pd.DataFrame, iqr_prefix: str, group_col: str, val_col: str, iqr_lower_quantile: float = 0.25, iqr_upper_quantile: float = 0.75, iqr_multiplier: float = 3.0) -&gt; pd.DataFrame</code>","text":"<p>Calculates the interquartile range (IQR) for each LSOA in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>iqr_prefix</code> <code>str</code> <p>Prefix for the IQR column names.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for IQR calculation.</p> required <code>val_col</code> <code>str</code> <p>The column containing values to calculate IQR.</p> required <code>iqr_lower_quantile</code> <code>float</code> <p>The lower quantile for IQR calculation.</p> <code>0.25</code> <code>iqr_upper_quantile</code> <code>float</code> <p>The upper quantile for IQR calculation.</p> <code>0.75</code> <code>iqr_multiplier</code> <code>float</code> <p>The multiplier for the IQR to determine outlier bounds.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with additional columns for IQR, outlier</p> <code>DataFrame</code> <p>bounds and 'threshold' columns, indicating which threshold the zscore</p> <code>DataFrame</code> <p>breached.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_lad_mean","title":"<code>calc_lad_mean(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculates the mean GDHI for each non outlier LSOA in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an added 'mean_non_out_gdhi' column.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_rate_of_change","title":"<code>calc_rate_of_change(df: pd.DataFrame, ascending: bool, sort_cols: list, group_col: str, val_col: str) -&gt; pd.DataFrame</code>","text":"<p>Calculate the rate of change going forward and backwards in time in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>ascending</code> <code>bool</code> <p>If True, calculates forward rate of change; otherwise, backward.</p> required <code>sort_cols</code> <code>list</code> <p>Columns to sort by before calculating rate of change.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for rate of change calculation.</p> required <code>val_col</code> <code>str</code> <p>The column for which the rate of change is calculated.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing the rate of change values.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_zscores","title":"<code>calc_zscores(df: pd.DataFrame, score_prefix: str, group_col: str, val_col: str, zscore_upper_threshold: float = 3.0, zscore_lower_threshold: float = -3.0) -&gt; pd.DataFrame</code>","text":"<p>Calculates the z-scores for percent changes and raw data in DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>score_prefix</code> <code>str</code> <p>Prefix for the zscore column names.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for z-score calculation.</p> required <code>val_col</code> <code>str</code> <p>The column values to calculate zscores.</p> required <code>zscore_upper_threshold</code> <code>float</code> <p>The upper threshold for z-score flag.</p> <code>3.0</code> <code>zscore_lower_threshold</code> <code>float</code> <p>The lower threshold for z-score flag.</p> <code>-3.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an additional 'zscore' and 'threshold'</p> <code>DataFrame</code> <p>columns, indicating which threshold the zscore breached.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess","title":"<code>gdhi_adj.preprocess.flag_preprocess</code>","text":"<p>Module for flagging preprocessing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess.create_master_flag","title":"<code>create_master_flag(df: pd.DataFrame, zscore_calculation: bool, iqr_calculation: bool) -&gt; pd.DataFrame</code>","text":"<p>Creates a master flag based on z score and IQR flag columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>zscore_calculation</code> <code>bool</code> <p>Whether z-score calculation is performed.</p> required <code>iqr_calculation</code> <code>bool</code> <p>Whether IQR calculation is performed.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an additional 'master_flag' columns.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess.flag_rollback_years","title":"<code>flag_rollback_years(df: pd.DataFrame, rollback_year_start: int, rollback_year_end: int) -&gt; pd.DataFrame</code>","text":"<p>Flags years where the GDHI has rolled back from future years. Typically 2010-2014 has 2015 data copied to them as it is missing.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>rollback_year_start</code> <code>int</code> <p>The start year for rollback flagging.</p> required <code>rollback_year_end</code> <code>int</code> <p>The end year for rollback flagging.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with an additional 'rollback_flag' column.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess","title":"<code>gdhi_adj.preprocess.join_preprocess</code>","text":"<p>Module for flagging preprocessing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess.concat_wide_dataframes","title":"<code>concat_wide_dataframes(df_wide_outlier: pd.DataFrame, df_wide_mean: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Concatenates two wide dataframes to create a final wide DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df_wide_outlier</code> <code>DataFrame</code> <p>The DataFrame containing outlier data.</p> required <code>df_wide_mean</code> <code>DataFrame</code> <p>The DataFrame containing mean data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The concatenated DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess.constrain_to_reg_acc","title":"<code>constrain_to_reg_acc(df: pd.DataFrame, reg_acc: pd.DataFrame, transaction_name: str) -&gt; pd.DataFrame</code>","text":"<p>Calculate contrained and unconstrained values for each outlier case.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame with outliers to be constrained.</p> required <code>reg_acc</code> <code>DataFrame</code> <p>The regional accounts DataFrame.</p> required <code>transaction_code</code> <code>str</code> <p>Transaction code to filter regional accounts.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The constrained DataFrame.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess","title":"<code>gdhi_adj.preprocess.pivot_preprocess</code>","text":"<p>Module for pivoting data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_output_long","title":"<code>pivot_output_long(df: pd.DataFrame, uncon_gdhi: str, con_gdhi: str) -&gt; pd.DataFrame</code>","text":"<p>Pivots the output DataFrame to long format. Args:     df (pd.DataFrame): The input DataFrame in wide format.     uncon_gdhi (str): The column name for unconstrained GDHI.     con_gdhi (str): The column name for constrained GDHI.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in long format.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_wide_dataframe","title":"<code>pivot_wide_dataframe(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame from long to wide format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame in long format.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_years_long_dataframe","title":"<code>pivot_years_long_dataframe(df: pd.DataFrame, new_var_col: str, new_val_col: str) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame based on specified index, columns, and values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>new_var_col</code> <code>str</code> <p>The name for the column containing old column names.</p> required <code>new_val_col</code> <code>str</code> <p>The name for the column containing values.</p> required <p>Returns: pd.DataFrame: The pivoted DataFrame.</p>"},{"location":"reference/#gdhi_adj.preprocess.run_preprocess","title":"<code>gdhi_adj.preprocess.run_preprocess</code>","text":"<p>Module for pre-processing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.run_preprocess.run_preprocessing","title":"<code>run_preprocessing(config: dict) -&gt; None</code>","text":"<p>Run the preprocessing steps for the GDHI adjustment project.</p> <p>This function performs the following steps: 1. Load the configuration settings. 2. Load the input data. 3. Pivot the DataFrame to long format. 4. Calculate percentage rate of change and flag rollback years. 5. Calculate z-scores and IQRs if desired as per config. 6. Create master flags. 7. Save interim data with all calculated values. 8. Calculate LAD mean GDHI. 9. Constrain outliers to regional accounts. 10. Pivot the DataFrame back to wide format. 11. Save the preprocessed data ready for PowerBI analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and</p> required <p>Returns:     None: The function does not return any value. It saves the processed     DataFrame to a CSV file.</p>"},{"location":"reference/#adjustment","title":"Adjustment","text":""},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment","title":"<code>gdhi_adj.adjustment.calc_adjustment</code>","text":"<p>Module for calculations to adjust data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment.extrapolate_imputed_val","title":"<code>extrapolate_imputed_val(df: pd.DataFrame, imputed_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculate the imputed value for a given LSOA code where the year that has been flagged as an outlier to adjust only has one valid safe year either side.</p> <p>The imputed value is extrapolated from the nearest safe year and the year 4 years after. This is to avoid short term fluctuations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with full data for lookup.</p> required <code>imputed_df</code> <code>DataFrame</code> <p>DataFrame to calculate imputed value.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame containing outlier imputed values.</p>"},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment.interpolate_imputed_val","title":"<code>interpolate_imputed_val(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculate the imputed value for a given LSOA code where the year that has been flagged as an outlier to adjust has a valid safe year either side.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with data to calculate imputed value.</p> required <p>Returns:     pd.DataFrame: DataFrame containing outlier imputed values.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment","title":"<code>gdhi_adj.adjustment.filter_adjustment</code>","text":"<p>Module for filtering adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_adjust","title":"<code>filter_adjust(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Filter data to keep only LSOAs for adjustment and subset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing LSOA data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered DataFrame with only relevant columns and rows.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_component","title":"<code>filter_component(df: pd.DataFrame, sas_code_filter: str, cord_code_filter: str, credit_debit_filter: str) -&gt; pd.DataFrame</code>","text":"<p>Filter DataFrame by component codes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Constrained DataFrame with component code data.</p> required <code>sas_code_filter</code> <code>str</code> <p>SAS code to filter by.</p> required <code>cord_code_filter</code> <code>str</code> <p>CORD code to filter by.</p> required <code>credit_debit_filter</code> <code>str</code> <p>Credit/Debit code to filter by.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered DataFrame containing only rows matching the</p> <code>DataFrame</code> <p>specified component codes.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_year","title":"<code>filter_year(df: pd.DataFrame, start_year: int, end_year: int) -&gt; pd.DataFrame</code>","text":"<p>Filter DataFrame by a range of years inclusively. Args:     df (pd.DataFrame): Input DataFrame containing year data.     start_year (int): Start year for filtering (inclusive).     end_year (int): End year for filtering (inclusive). Returns:     pd.DataFrame: Filtered DataFrame containing only rows within the year     range.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment","title":"<code>gdhi_adj.adjustment.join_adjustment</code>","text":"<p>Module for joining adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment.join_analyst_constrained_data","title":"<code>join_analyst_constrained_data(df_constrained: pd.DataFrame, df_analyst: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Join analyst data to constrained data based on LSOA code and LAD code.</p> <p>Parameters:</p> Name Type Description Default <code>df_constrained</code> <code>DataFrame</code> <p>DataFrame containing constrained data.</p> required <code>df_analyst</code> <code>DataFrame</code> <p>DataFrame containing analyst data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Joined DataFrame with relevant columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment.join_analyst_unconstrained_data","title":"<code>join_analyst_unconstrained_data(df_unconstrained: pd.DataFrame, df_analyst: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Join analyst data to unconstrained data based on LSOA code and LAD code.</p> <p>Parameters:</p> Name Type Description Default <code>df_unconstrained</code> <code>DataFrame</code> <p>DataFrame with unconstrained data.</p> required <code>df_analyst</code> <code>DataFrame</code> <p>DataFrame containing analyst data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Joined DataFrame with relevant columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment","title":"<code>gdhi_adj.adjustment.pivot_adjustment</code>","text":"<p>Module for pivoting adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment.pivot_adjustment_long","title":"<code>pivot_adjustment_long(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Un-pivot (melt) the adjustment DataFrame from wide to long format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing data to be adjusted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Pivoted DataFrame in long format.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment.pivot_wide_final_dataframe","title":"<code>pivot_wide_final_dataframe(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame from long to wide format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame in long format.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment","title":"<code>gdhi_adj.adjustment.reformat_adjustment</code>","text":"<p>Module for joining adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment.reformat_adjust_col","title":"<code>reformat_adjust_col(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Reformat data within the adjust column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be reformatted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with reformatted columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment.reformat_year_col","title":"<code>reformat_year_col(df: pd.DataFrame, start_year: int, end_year: int) -&gt; pd.DataFrame</code>","text":"<p>Reformat data within the year column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be reformatted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with reformatted columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.run_adjustment","title":"<code>gdhi_adj.adjustment.run_adjustment</code>","text":"<p>Module for adjusting data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.run_adjustment.run_adjustment","title":"<code>run_adjustment(config: dict) -&gt; None</code>","text":"<p>Run the adjustment steps for the GDHI adjustment project.</p> <p>This function performs the following steps: 1. Load the configuration settings. 2. Load the input data. 3. Reformat adjust and year columns. 4. Filter of data for adjustment. 5. Join analyst output with constrained and unconstrained data. 6. Pivot the DataFrame to long format for manipulation. 7. Filter data by the specified year range. 8. Calculate the imputed gdhi values for outlier years. 9. Calculate adjustment values based on imputed gdhi. 10. Apportion adjustment values to all years. 11. Save interim data with all calculated values. 12. Pivot data to wide format for PowerBI QA reiteration. 13. Pivot final DataFrame to wide format for exporting. 14. Save the final adjusted data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and</p> required <p>Returns:     None: The function does not return any value. It saves the processed     DataFrame to a CSV file.</p>"},{"location":"reference/#mapping","title":"Mapping","text":""},{"location":"reference/#gdhi_adj.mapping.mapping_main","title":"<code>gdhi_adj.mapping.mapping_main</code>","text":"<p>Mapping functions for local authority units mapped to LADs.</p>"},{"location":"reference/#utilities","title":"Utilities","text":""},{"location":"reference/#gdhi_adj.utils.helpers","title":"<code>gdhi_adj.utils.helpers</code>","text":"<p>Define helper functions that wrap regularly-used functions.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.convert_column_types","title":"<code>convert_column_types(df: pd.DataFrame, schema: dict, logger: logging.Logger) -&gt; pd.DataFrame</code>","text":"<p>Convert DataFrame columns data types as specified in the schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to convert column types.</p> required <code>schema</code> <code>dict</code> <p>The schema containing column names and their expected</p> required <code>logger</code> <code>Logger</code> <p>Logger for logging conversion actions.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with converted column types.</p> <p>Raises:</p> Type Description <code>warning</code> <p>If a column's type conversion fails.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.load_schema_from_toml","title":"<code>load_schema_from_toml(schema_path: str) -&gt; dict</code>","text":"<p>Load a schema from a TOML file.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path</code> <code>str</code> <p>Path to the TOML schema file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the schema.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.load_toml_config","title":"<code>load_toml_config(path: Union[str, pathlib.Path]) -&gt; dict | None</code>","text":"<p>Load a .toml file from a path, with logging and safe error handling.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>The path to load the .toml file from.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: The loaded toml file as a dictionary, or None on error.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.read_with_schema","title":"<code>read_with_schema(input_file_path: str, input_schema_path: str) -&gt; pd.DataFrame</code>","text":"<p>Reads in a csv file and compares it to a data dictionary schema.</p> <p>Parameters:</p> Name Type Description Default <code>input_file_path</code> <code>string</code> <p>Filepath to the csv file to be read in.</p> required <code>input_schema_path</code> <code>string</code> <p>Filepath to the schema file in TOML format.</p> required <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Formatted dataFrame containing data from the csv</p> <code>DataFrame</code> <p>file.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.rename_columns","title":"<code>rename_columns(df: pd.DataFrame, schema: dict, logger: logging.Logger) -&gt; pd.DataFrame</code>","text":"<p>Rename columns in the DataFrame based on the schema. Schema should be a dict where keys are new column names and values are dicts with 'old_name'.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to rename columns in.</p> required <code>schema</code> <code>dict</code> <p>The schema containing old and new column names.</p> required <code>logger</code> <code>Logger</code> <p>Logger for logging renaming actions.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with renamed columns.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.validate_schema","title":"<code>validate_schema(df: pd.DataFrame, schema: dict)</code>","text":"<p>Validate the DataFrame against the schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to validate.</p> required <code>schema</code> <code>dict</code> <p>The schema sourced from a TOML file to validate against.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If a required column fromt he scheda is missing in the</p> <code>TypeError</code> <p>If a column's type does not match the expected type in the</p>"},{"location":"reference/#gdhi_adj.utils.helpers.write_with_schema","title":"<code>write_with_schema(df: pd.DataFrame, output_schema_path: str, output_dir: str, new_filename=None)</code>","text":"<p>Writes a DataFrame to a CSV file, renaming columns and validating against a schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The final output DataFrame to write to CSV.</p> required <code>output_schema_path</code> <code>str</code> <p>Path to the output schema file in TOML</p> required <code>output_dir</code> <code>str</code> <p>Directory where the CSV file will be saved.</p> required <code>new_filename</code> <code>str</code> <p>New filename for the output CSV. If None,                           uses the original name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the DataFrame does not match the schema.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>Writes the DataFrame to a CSV file after validating against the</p> <p>schema.</p>"},{"location":"reference/#gdhi_adj.utils.logger","title":"<code>gdhi_adj.utils.logger</code>","text":""},{"location":"reference/#gdhi_adj.utils.logger.CustomFormatter","title":"<code>CustomFormatter</code>","text":"<p>               Bases: <code>Formatter</code></p> <p>Define logging formatter with colors for different log levels.</p>"},{"location":"reference/#gdhi_adj.utils.logger.CustomFormatter.format","title":"<code>format(record)</code>","text":"<p>Set color formatting for logger.</p>"},{"location":"reference/#gdhi_adj.utils.logger.GDHI_adj_logger","title":"<code>GDHI_adj_logger(name)</code>","text":"<p>Custom logging class for use throughout the GDHI_adj pipeline.</p>"},{"location":"reference/#gdhi_adj.utils.logger.GDHI_adj_logger--parameters","title":"Parameters","text":"<p>name : str     The name of the file the logger is being created from.</p> <p>Initialise the logger class.</p>"}]}